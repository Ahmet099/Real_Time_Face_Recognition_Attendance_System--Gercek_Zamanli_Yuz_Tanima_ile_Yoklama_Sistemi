import os
import cv2
import dlib
import numpy as np
import pickle
from scipy.spatial import distance
import attendance_manager

# Dlib yÃ¼z tespit ve tanÄ±ma modelleri
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
face_rec_model = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")

# KayÄ±tlÄ± Ã¶ÄŸrenci embedding'lerinin bulunduÄŸu dosya
STUDENT_DB = "student_encodings.pkl"

# TanÄ±ma iÃ§in eÅŸik deÄŸeri: Euclidean mesafe THRESHOLD'un altÄ±ndaysa eÅŸleÅŸme var demektir.
THRESHOLD = 0.6  # Ä°htiyaca gÃ¶re ayarlayÄ±n

def get_face_embedding(image, face):
    """
    Verilen yÃ¼z bÃ¶lgesinin embedding'ini hesaplar.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    shape = predictor(gray, face)
    return np.array(face_rec_model.compute_face_descriptor(image, shape))

def register_student(student_id, num_images=20):
    """
    Ã–ÄŸrenci kaydÄ± yaparken, kameradan alÄ±nan gÃ¶rÃ¼ntÃ¼lerdeki yÃ¼zleri tespit eder,
    her yÃ¼zÃ¼n embedding'lerini hesaplar ve bunlarÄ±n ortalamasÄ±nÄ± kaydeder.
    AyrÄ±ca, kaydedilen yÃ¼z gÃ¶rÃ¼ntÃ¼leri "data/train/<student_id>" klasÃ¶rÃ¼ne kaydedilir.
    """
    save_dir = os.path.join("data", "train", student_id)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        print(f"ğŸ“ OluÅŸturuldu: {save_dir}")

    cap = cv2.VideoCapture(0)
    count = 0
    embeddings = []
    print(f"ğŸ“¸ {student_id} iÃ§in kayÄ±t baÅŸlatÄ±ldÄ±. {num_images} adet gÃ¶rÃ¼ntÃ¼ alÄ±nacak. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n.")

    while count < num_images:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)
        if len(faces) > 0:
            face = faces[0]  # Ä°lk tespit edilen yÃ¼zÃ¼ kullan
            x, y, w, h = face.left(), face.top(), face.width(), face.height()
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)
            embedding = get_face_embedding(frame, face)
            if embedding is not None:
                embeddings.append(embedding)
                filename = os.path.join(save_dir, f"{student_id}_{count}.jpg")
                face_img = frame[y:y+h, x:x+w]
                cv2.imwrite(filename, face_img)
                count += 1
                print(f"{count}. gÃ¶rÃ¼ntÃ¼ kaydedildi: {filename}")
        cv2.imshow("Ã–ÄŸrenci KaydÄ±", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

    if embeddings:
        avg_embedding = np.mean(embeddings, axis=0)
        # Mevcut Ã¶ÄŸrenci embedding'lerini yÃ¼kle veya yeni bir sÃ¶zlÃ¼k oluÅŸtur
        if os.path.exists(STUDENT_DB):
            with open(STUDENT_DB, "rb") as f:
                student_encodings = pickle.load(f)
        else:
            student_encodings = {}
        student_encodings[student_id] = avg_embedding
        with open(STUDENT_DB, "wb") as f:
            pickle.dump(student_encodings, f)
        print(f"âœ… Ã–ÄŸrenci {student_id} kaydÄ± tamamlandÄ±, ortalama embedding kaydedildi.")
    else:
        print("âŒ HiÃ§bir yÃ¼z tespit edilemedi, Ã¶ÄŸrenci kaydÄ± baÅŸarÄ±sÄ±z oldu.")

def predict_from_camera():
    """
    Kamera Ã¼zerinden gerÃ§ek zamanlÄ± yÃ¼z tanÄ±masÄ± yapar.
    KayÄ±tlÄ± Ã¶ÄŸrenci embedding'leri ile karÅŸÄ±laÅŸtÄ±rma yaparak en yakÄ±n eÅŸleÅŸmeyi bulur.
    EÄŸer mesafe THRESHOLD'un altÄ±ndaysa eÅŸleÅŸme var demektir; aksi halde 'unknown' olarak atanÄ±r.
    TanÄ±nan Ã¶ÄŸrenci iÃ§in attendance_manager.add_attendance_record() Ã§aÄŸrÄ±lÄ±r.
    """
    if not os.path.exists(STUDENT_DB):
        print("âš ï¸ Ã–ÄŸrenci kayÄ±t veritabanÄ± bulunamadÄ±. LÃ¼tfen Ã¶nce Ã¶ÄŸrenci kaydÄ± yapÄ±n!")
        return

    with open(STUDENT_DB, "rb") as f:
        students = pickle.load(f)

    cap = cv2.VideoCapture(0)
    print("ğŸ” GerÃ§ek zamanlÄ± yÃ¼z tanÄ±ma baÅŸladÄ±. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n.")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)

        for face in faces:
            x, y, w, h = face.left(), face.top(), face.width(), face.height()
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)
            embedding = get_face_embedding(frame, face)
            if embedding is None:
                continue

            min_dist = float("inf")
            best_match = "unknown"
            for student_id, saved_embedding in students.items():
                dist = distance.euclidean(saved_embedding, embedding)
                if dist < THRESHOLD and dist < min_dist:
                    min_dist = dist
                    best_match = student_id

            cv2.putText(frame, f"{best_match} ({min_dist:.2f})", (x, y-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

            if best_match == "unknown":
                cv2.putText(frame, "KayÄ±t bulunamadÄ±", (x, y+h+20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)
            else:
                attendance_manager.add_attendance_record(best_match)

        cv2.imshow("Real-Time Face Recognition", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    # Ã–rneÄŸin, test iÃ§in:
    # register_student("stu001", num_images=20)
    predict_from_camera()